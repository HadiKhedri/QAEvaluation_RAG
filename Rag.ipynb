{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain\n",
    "pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings.py\n",
    "import os\n",
    "from os.path import join, dirname\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"DataSet.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Persistence Pays Chapter 1 “Why can’t we come in?,” I asked the large man standing in front of us. He was wearing a dark suit, and he was tall and strong. He was blocking the door to Zara’s Nightclub. We could hear the loud dance music behind the door. We wanted to go in! I had lost my job the other day. I needed to have a night of fun! I didn’t want to have a lot of stress, so we had to ﬁnd a way to get inside! The tall man was a bouncer; his job was to let the “right” people in, and to keep'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.page_content[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'DataSet.pdf', 'page': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=50,\n",
    "    chunk_overlap=10,\n",
    "    length_function=len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "286"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"i like dogs\"\n",
    "sentence2 = \"i like canines\"\n",
    "sentence3 = \"the weather is ugly outside\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding1 = embedding.embed_query(sentence1)\n",
    "embedding2 = embedding.embed_query(sentence2)\n",
    "embedding3 = embedding.embed_query(sentence3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install chromadb    # installed Croma Succesfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = 'docs/chroma/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./docs/chroma  # remove old database files if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                      RAG using Lama 2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pylance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install GPT4All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install git+https://github.com/ethereum/web3.py.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('</Users/macbookpro/Library/Python/3.9/lib/python/site-packages>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   .   .   .   .   .   .   .   .   .   .**Start**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "#from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "\n",
    "#For txt file\n",
    "#loader = TextLoader(\"Hadi.txt\")\n",
    "#data = loader.load()\n",
    "\n",
    "\n",
    "#Load Pdf Files\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"DataSet.pdf\")\n",
    "data = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split text function:\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "\tchunk_size=200, chunk_overlap=10, ##separators=[\"\\n\\n\", \"\\n\", \"\\. \", \" \", \"\"]\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split texts \n",
    "all_splits = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "827"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_load_from_file: gguf version     = 2\n",
      "bert_load_from_file: gguf alignment   = 32\n",
      "bert_load_from_file: gguf data offset = 695552\n",
      "bert_load_from_file: model name           = BERT\n",
      "bert_load_from_file: model architecture   = bert\n",
      "bert_load_from_file: model file type      = 1\n",
      "bert_load_from_file: bert tokenizer vocab = 30522\n"
     ]
    }
   ],
   "source": [
    "#Embed to vector \n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=GPT4AllEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the bouncer’s job at Zara’s\"\n",
    "prompt = \" Answer based on data provided in one sentence only\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search similar chunks\n",
    "docs = vectorstore.similarity_search(question, k = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='square\\nroot\\nfunctions,\\nfollow\\nthese\\nsteps:', metadata={'page': 0, 'source': 'document.pdf'}),\n",
       " Document(page_content='is\\n2\\nbecause\\nthe\\nhighest\\npower\\nof\\nthe\\nvariable,\\nx,\\nis\\n2.\\nDo\\nyou\\nhave\\nany\\nfollow-up\\nquestions\\nabout\\npolynomials\\nor\\ntheir\\ndegrees?\\n\"To\\nsolve\\nsquare\\nroot\\nfunctions,\\nyou\\ncan\\nfollow\\nthese\\nsteps:\\n1.\\nStart', metadata={'page': 26, 'source': 'document.pdf'}),\n",
       " Document(page_content='1.\\nStart\\nby\\nisolating\\nthe\\nsquare\\nroot\\nterm\\non\\none\\nside\\nof\\nthe\\nequation.\\n2.\\nSquare\\nboth\\nsides\\nof\\nthe\\nequation\\nto\\nremove\\nthe\\nsquare\\nroot.\\n3.\\nSolve\\nfor\\nthe\\nvariable.', metadata={'page': 26, 'source': 'document.pdf'}),\n",
       " Document(page_content='1.\\nIsolate\\nthe\\nsquare\\nroot\\nterm:\\nMove\\nany\\nconstant\\nterms\\nto\\nthe\\nother\\nside\\nof\\nthe\\nequation,\\nleaving\\nonly\\nthe\\nsquare\\nroot\\nterm\\non\\none\\nside.\\n2.\\nSquare\\nboth\\nsides\\nof\\nthe\\nequation:\\nThis\\nwill\\neliminate\\nthe', metadata={'page': 1, 'source': 'document.pdf'})]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "town to come to Zara’s. The new club was famous and we wanted to check it out. But, the bouncer did not reply. Instead, he looked over my skinny shoulder. There was a long line of people behind me. \n",
      "************\n",
      "\n",
      "“Clearly,” the redhead said. Her friends laughed, but I laughed with them. A little. “Would you like to go to Zara’s with us? The bouncer would not let us in,” I said. “But maybe, we could get in with \n",
      "************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print all chunks:\n",
    "for i in range(len(docs)):\n",
    "\tprint(docs[i].page_content ,\"\\n************\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Lama2 model:\n",
    "llm = Ollama(model=\"llama2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Machin response:\n",
    "Machine_response = llm.invoke(docs[0].page_content+question+prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bouncer's job at Zara's is to check and screen people who want to enter the club. This is evident from the sentence \"But, the bouncer did not reply. Instead, he looked over my skinny shoulder.\" The bouncer is not just standing at the door, but is actively checking and screening people before allowing them to enter the club.\n"
     ]
    }
   ],
   "source": [
    "print(Machine_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gives Human response:\n",
    "Human_response = \" The Bouncer is A being a Security guard and monitoring people in zara dance club\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = \"how similare are these two paragraph in meaning? give 10 if they are identical and 1 if they are total different\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "Machine_response1 = llm.invoke(Machine_response+Human_response+query1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The two paragraphs are similar in meaning as both describe the bouncer's job at Zara's, which is to check and screen people before allowing them to enter the club. However, there are some differences between the two paragraphs:\n",
      "\n",
      "1. The first paragraph mentions that the bouncer is \"standing at the door,\" while the second paragraph says he is \"looking over [the speaker's] skinny shoulder.\" This suggests that the bouncer is actively patrolling the area around the door, rather than just standing in one place.\n",
      "2. The first paragraph uses the phrase \"check and screen people,\" while the second paragraph uses \"looked over [the speaker's] shoulder.\" This implies that the bouncer is actively scanning the area for potential threats or problems, rather than simply standing at the door.\n",
      "3. The first paragraph does not mention the bouncer's role as a dancer and singer in Zara's dance club, while the second paragraph highlights this aspect of his job.\n",
      "4. The first paragraph does not mention the bouncer playing piano at Zara's, while the second paragraph mentions this.\n",
      "\n",
      "Overall, while both paragraphs describe the bouncer's job at Zara's, there are some differences in the language and details used. Therefore, I would rate them as follows:\n",
      "\n",
      "Identical: 3 (The bouncer's job is to check and screen people before allowing them to enter the club)\n",
      "Similar but not identical: 7 (Both paragraphs describe the bouncer's job at Zara's, but there are some differences in the language and details used)\n",
      "Total different: 1 (The two paragraphs describe completely different jobs and contexts)\n",
      "\n",
      "\n",
      " The Bouncer is A being a dancer and singer in zara dance club and playing piano there \n"
     ]
    }
   ],
   "source": [
    "print(Machine_response1)\n",
    "print(\"\\n\")\n",
    "print(Human_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_load_from_file: gguf version     = 2\n",
      "bert_load_from_file: gguf alignment   = 32\n",
      "bert_load_from_file: gguf data offset = 695552\n",
      "bert_load_from_file: model name           = BERT\n",
      "bert_load_from_file: model architecture   = bert\n",
      "bert_load_from_file: model file type      = 1\n",
      "bert_load_from_file: bert tokenizer vocab = 30522\n"
     ]
    }
   ],
   "source": [
    "gpt4all_embd = GPT4AllEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_result = gpt4all_embd.embed_documents([Human_response])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bouncer's job at Zara's is to check and screen people who want to enter the club. This is evident from the sentence \"But, the bouncer did not reply. Instead, he looked over my skinny shoulder.\" The bouncer is not just standing at the door, but is actively checking and screening people before allowing them to enter the club.\n",
      "\n",
      "\n",
      " The Bouncer is A being a security gaurd in zara dance club and screening people who want enter  \n"
     ]
    }
   ],
   "source": [
    "print(Machine_response)\n",
    "print(\"\\n\")\n",
    "print(Human_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between text1 and text2: [[0.79687688]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "text1 = Machine_response\n",
    "text2 = Human_response\n",
    "\n",
    "# Create CountVectorizer instance\n",
    "#vectorizer = CountVectorizer()\n",
    "\n",
    "doc_result = gpt4all_embd.embed_documents([Machine_response])\n",
    "doc_result1 = gpt4all_embd.embed_documents([Human_response])\n",
    "\n",
    "\n",
    "# Calculate cosine similarity between text1 and text2\n",
    "similarity_text1_text2 = cosine_similarity(doc_result, doc_result1)\n",
    "\n",
    "print(\"Cosine Similarity between text1 and text2:\", similarity_text1_text2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
